# VideoMimic 观测计算完整流程说明

## 一、观测配置位置

### 1. 主配置文件
**位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic_config.py:626-637`

```python
env = LeggedRobotEnvCfg(
    num_actions = 23,  # G1机器人23个控制关节
    
    # 观测列表（定义需要计算哪些观测）
    obs = [
        'torso',                    # 躯干基础观察
        'torso_real',               # 躯干真实观察（带噪声，用于sim2real）
        'deepmimic',                # 深度模仿参考数据（完整动作信息）
        'teacher',                  # 教师观察（用于蒸馏）
        'deepmimic_lin_ang_vel',    # 目标线速度+角速度（根方向）
        'terrain_height',           # 地形高度场（清洁版）
        'terrain_height_noisy',     # 地形高度场（带噪声）
        'root_height',              # 根部高度（单点）
        'phase',                    # 动作相位
        'torso_xy_rel',             # 躯干XY相对位置（根方向）
        'torso_yaw_rel',            # 躯干偏航相对角度（根方向）
        'torso_xy',                 # 躯干XY绝对位置
        'torso_yaw',                # 躯干偏航绝对角度
        'target_joints',            # ★目标关节位置（参考）
        'target_root_roll',         # ★目标根部滚转（参考）
        'target_root_pitch',        # ★目标根部俯仰（参考）
        'target_root_yaw',          # 目标根部偏航
        'upper_body_joint_targets', # 上身关节目标
        'teacher_checkpoint_index', # 教师检查点索引（多教师）
    ],
    
    # 历史观测配置（定义哪些观测需要保存过去N帧）
    obs_history = {
        'torso_real': 5,            # 本体感知保存5帧
        'torso_xy_rel': 5,          # 相对XY保存5帧
        'torso_yaw_rel': 5,         # 相对偏航保存5帧
        'torso_xy': 5,              # 绝对XY保存5帧
        'torso_yaw': 5,             # 绝对偏航保存5帧
        'deepmimic_lin_ang_vel': 5, # 目标速度保存5帧
    }
)
```

## 二、观测函数注册

### 2. 函数注册机制
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/legged_robot.py:866-889`
**调用时机**: `LeggedRobot.__init__()` 初始化时

```python
def _prepare_observation_function(self):
    """
    准备观测函数列表
    根据cfg.env.obs动态注册所有观测函数
    """
    self.observation_functions = []  # 存储函数对象
    self.observation_names = []      # 存储函数名称
    
    for name in self.cfg.env.obs:  # 遍历配置的obs列表
        if name in self.sensors:
            # 【传感器观测】terrain_height, root_height等
            self.observation_functions.append(
                lambda sensor_name=name: self._obs_sensor(sensor_name)
            )
        else:
            # 【函数观测】torso_real, deepmimic等
            func_name = f'_obs_{name}'  # 构造函数名：_obs_torso_real
            
            if hasattr(self, func_name):
                self.observation_functions.append(getattr(self, func_name))
            else:
                # 特殊处理teacher观测
                if name == 'teacher':
                    self.observation_functions.append(
                        lambda: torch.zeros(self.num_envs, 415, device=self.device)
                    )
                else:
                    raise ValueError(f"缺少观测方法 {func_name}")
        
        self.observation_names.append(name)

# 注册后的结果：
# observation_names[0] = 'torso'
# observation_functions[0] = _obs_torso
# observation_names[1] = 'torso_real'
# observation_functions[1] = _obs_torso_real
# ... 以此类推
```

## 三、观测计算主函数

### 3. compute_observations 核心逻辑
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/legged_robot.py:304-326`
**调用时机**: 
- 初始化时通过 `get_obs_shapes()` 触发
- 每次 `post_physics_step()` 结束时调用

```python
def compute_observations(self):
    """计算所有观测值"""
    
    # ===== 步骤1：计算所有基础观测 =====
    self.obs_dict = {}
    
    for i, obs_fn in enumerate(self.observation_functions):
        obs_name = self.observation_names[i]
        # 调用对应的观测函数
        self.obs_dict[obs_name] = obs_fn()
    
    # 此时obs_dict包含：
    # {
    #     'torso': (4096, 52),
    #     'torso_real': (4096, 75),
    #     'deepmimic': (4096, 129),
    #     'target_joints': (4096, 23),
    #     'torso_xy_rel': (4096, 2),
    #     'torso_yaw_rel': (4096, 1),
    #     'terrain_height': (4096, 100),
    #     ...
    # }
    
    # ===== 步骤2：初始化历史处理器（仅第一次）=====
    if self.history_handler is None and hasattr(self.cfg.env, 'obs_history'):
        from legged_gym.utils.history import HistoryHandler
        
        # 提取观测维度信息
        obs_dims = {k: v.shape[1:] for k, v in self.obs_dict.items()}
        
        # 创建历史管理器
        self.history_handler = HistoryHandler(
            self.num_envs,              # 4096个环境
            self.cfg.env.obs_history,   # {'torso_real': 5, ...}
            obs_dims,                   # {'torso_real': (75,), ...}
            self.device
        )
    
    # ===== 步骤3：更新历史观测 =====
    if self.history_handler is not None:
        # 添加当前帧到历史缓冲区
        for key in self.cfg.env.obs_history.keys():
            self.history_handler.add(key, self.obs_dict[key])
        
        # 查询历史并添加到obs_dict
        for key in self.cfg.env.obs_history.keys():
            self.obs_dict[f'history_{key}'] = self.history_handler.query(key)
    
    # 此时obs_dict新增：
    # {
    #     'history_torso_real': (4096, 375),      # 75*5
    #     'history_torso_xy_rel': (4096, 10),     # 2*5
    #     'history_torso_yaw_rel': (4096, 5),     # 1*5
    #     ...
    # }
    
    # ===== 步骤4：添加教师观测 =====
    self.obs_dict['teacher'] = self._manual_obs_teacher()
    
    return self.obs_dict
```

## 四、核心观测函数详解

### 4.1 本体感知 (_obs_torso_real)
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:678-698`
**用途**: 机器人自身状态感知（可部署到真实机器人）

```python
def _obs_torso_real(self):
    """
    真实躯干观察
    
    组成部分：
    1. 角速度 (3维): 机器人旋转速度
    2. 重力方向 (3维): IMU重力投影
    3. 关节位置 (23维): 当前关节角度
    4. 关节速度 (23维): 关节运动速度  
    5. 动作历史 (23维): 上一步执行的动作
    
    总维度：3+3+23+23+23 = 75
    """
    obs = torch.cat((  
        # [1] 基座角速度，归一化
        self.base_ang_vel * self.obs_scales.ang_vel,  # (4096, 3)
        
        # [2] 投影重力方向 + episode固定噪声
        self.projected_gravity + 
        self.gravity_rand_seed * self.cfg.noise.offset_scales.gravity,  # (4096, 3)
        
        # [3] 关节位置（相对默认）+ episode固定噪声
        (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos + 
        self.dof_pos_rand_seed * self.cfg.noise.offset_scales.dof_pos,  # (4096, 23)
        
        # [4] 关节速度，归一化
        self.dof_vel * self.obs_scales.dof_vel,  # (4096, 23)
        
        # [5] 上一次执行的动作
        self.actions,  # (4096, 23)
    ), dim=-1)
    
    # 初始化噪声缩放向量（仅第一次）
    if not hasattr(self, 'obs_torso_real_noise_scale'):
        self.obs_torso_real_noise_scale = self._get_noise_scale_vec_torso_real(obs)
    
    # 添加每步独立的随机噪声
    if self.add_noise:
        obs += (2 * torch.rand_like(obs) - 1) * self.obs_torso_real_noise_scale
    
    return obs  # (4096, 75)
```

### 4.2 深度模仿参考 (_obs_deepmimic)
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:891-964`
**用途**: 提供完整的参考动作信息

```python
def _obs_deepmimic(self):
    """
    深度模仿观察（核心参考数据！）
    
    包含从动作捕捉数据提取的完整参考信息：
    1. 跟踪链接高度 (13维)
    2. 目标根部四元数 (4维) - 相对当前姿态
    3. 目标根部位置 (3维) - 相对当前位置
    4. 目标关节位置 (23维) - 相对当前关节
    5. 目标身体部位位置 (39维=13*3) - 相对当前位置
    6. 目标身体部位速度 (39维=13*3)
    7. 接触信息 (8维=2+2+2+2): 当前接触+目标接触+上次接触+无效变化
    
    总维度：13+4+3+23+39+39+8 = 129
    """
    K = self.cfg.deepmimic.num_next_obs  # 通常=1，向前看1帧
    
    # ===== 步骤1：从回放数据获取目标状态 =====
    state = self.replay_data_loader.get_next_data(K=K)
    # state包含动作捕捉数据的下一帧：
    # - root_pos, root_quat: 根部位置和姿态
    # - motors: 关节角度
    # - link_pos, link_vels: 身体部位位置和速度
    # - contacts: 脚部接触状态
    
    target_root_pos = state.root_pos       # (4096, 1, 3)
    target_root_quat = state.root_quat     # (4096, 1, 4)
    target_motors = state.motors           # (4096, 1, 23)
    target_link_pos = state.link_pos       # (4096, 1, 13, 3)
    target_link_vel = state.link_vels      # (4096, 1, 13, 3)
    target_contacts = state.contacts       # (4096, 1, 2)
    
    # ===== 步骤2：转换到机器人局部坐标系 =====
    torso_rot = self.root_states[:, 3:7]
    heading = calc_heading_quat_inv(torso_rot)  # 偏航逆四元数
    
    # [1] 相对根部位置（局部坐标系）
    obs_root_pos = target_root_pos - self.env_root_pos.unsqueeze(1)
    obs_root_pos = quat_rotate(heading, obs_root_pos)  # 转到局部坐标
    
    # [2] 相对根部四元数
    obs_root_quat = quat_mul(
        target_root_quat, 
        quat_conjugate(torso_rot.unsqueeze(1).repeat(1, K, 1))
    )
    
    # [3] 相对关节位置
    obs_joints = target_motors - self.dof_pos.unsqueeze(1)
    
    # [4] 相对身体部位位置（局部坐标系）
    current_tracked_link_pos = self.env_rigid_body_pos[:, self.tracked_body_indices]
    obs_link_pos = (target_link_pos - current_tracked_link_pos.unsqueeze(1))
    obs_link_pos = quat_rotate(heading, obs_link_pos)  # 转到局部坐标
    
    # ===== 步骤3：获取链接高度（从传感器）=====
    obs_tracked_link_heights = self.get_sensor_data('link_heights')
    # 13个跟踪身体部位距地面的高度
    
    # ===== 步骤4：转换身体部位速度（局部坐标系）=====
    link_vels_global = self.rigid_body_vel[:, self.tracked_body_indices]
    obs_link_vel = quat_rotate(heading, link_vels_global)
    
    # ===== 步骤5：组合所有观测 =====
    obs = torch.cat((
        obs_tracked_link_heights.view(self.num_envs, -1),  # 13
        obs_root_quat.view(self.num_envs, -1),             # 4
        obs_root_pos.view(self.num_envs, -1),              # 3
        obs_joints.view(self.num_envs, -1),                # 23
        obs_link_pos.view(self.num_envs, -1),              # 39
        obs_link_vel.view(self.num_envs, -1),              # 39
    ), dim=-1)  # 总共：121维
    
    # ===== 步骤6：添加接触信息 =====
    if self.cfg.deepmimic.contact_names is not None:
        # 当前接触状态
        contact = self.contact_forces[:, self.feet_indices, 2] > 1.
        
        # 检测无效接触变化
        contact_changed = contact != self.last_contact_state
        target_changed = self.target_contacts != self.last_target_contact
        current_is_wrong = contact != self.target_contacts
        invalid_changes = contact_changed & ~target_changed & current_is_wrong
        
        obs = torch.cat((
            obs,                                                    # 121
            contact.float().view(self.num_envs, -1),                # 2: 当前接触
            target_contacts.float().view(self.num_envs, -1),        # 2: 目标接触
            self.last_contact_state.float().view(self.num_envs, -1),# 2: 上次接触
            invalid_changes.float().view(self.num_envs, -1),        # 2: 无效变化
        ), dim=-1)  # 总共：129维
    
    return obs  # (4096, 129)
```

### 4.3 目标速度 (_obs_deepmimic_lin_ang_vel) - 根方向核心
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:973-1028`
**用途**: 提供移动方向信息（蒸馏平面策略仅用此观测）

```python
def _obs_deepmimic_lin_ang_vel(self):
    """
    目标线速度和角速度观察（根方向！）
    
    这是"蒸馏平面策略"唯一的参考输入
    只告诉机器人往哪个方向移动，不告诉具体关节怎么动
    
    维度：3+3 = 6
    """
    K = 1
    state = self.replay_data_loader.get_next_data(K=K)
    target_root_vel = state.root_vel         # 目标线速度 (4096, 1, 3)
    target_root_ang_vel = state.root_ang_vel # 目标角速度 (4096, 1, 3)
    
    torso_rot = self.root_states[:, 3:7]
    heading = calc_heading_quat_inv(torso_rot)
    
    # ===== 手动控制模式（用于测试）=====
    if hasattr(self, 'viser_viz') and self.viser_viz.manual_control.value:
        manual_lin_vel = torch.zeros((self.num_envs, 3), device=self.device)
        manual_ang_vel = torch.zeros((self.num_envs, 3), device=self.device)
        
        lin_vel_scale = 0.5   # 线速度缩放：0.5 m/s
        ang_vel_scale = 1.0   # 角速度缩放：1.0 rad/s
        
        # 根据键盘/手柄输入设置速度
        if self.viser_viz.move_forward.value:
            manual_lin_vel[:, 0] = lin_vel_scale   # 向前
        if self.viser_viz.move_back.value:
            manual_lin_vel[:, 0] = -lin_vel_scale  # 向后
        if self.viser_viz.rotate_left.value:
            manual_ang_vel[:, 2] = ang_vel_scale   # 左转
        # ... 其他方向
        
        obs_lin_vel = manual_lin_vel
        obs_ang_vel = manual_ang_vel
    else:
        # ===== 自动模式：使用回放数据 =====
        # 转换到机器人局部坐标系
        obs_lin_vel = quat_rotate(heading, target_root_vel.squeeze(1))
        obs_ang_vel = quat_rotate(heading, target_root_ang_vel.squeeze(1))
    
    obs = torch.cat((
        obs_lin_vel.view(self.num_envs, -1),  # 3维
        obs_ang_vel.view(self.num_envs, -1),  # 3维
    ), dim=-1)
    
    # 添加噪声（提高鲁棒性）
    if not hasattr(self, 'obs_lin_ang_vel_noise_scale'):
        self.obs_lin_ang_vel_noise_scale = self._get_noise_scale_vec_lin_ang_vel(obs)
    
    if self.add_noise:
        obs += (2 * torch.rand_like(obs) - 1) * self.obs_lin_ang_vel_noise_scale
    
    return obs  # (4096, 6)
```

### 4.4 相对位置 (_obs_torso_xy_rel) - 根方向组件
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:710-768`

```python
def _obs_torso_xy_rel(self):
    """
    躯干XY相对位置（根方向组件！）
    
    告诉机器人目标躯干在哪个方向、多远
    但不告诉具体怎么移动四肢
    
    维度：2
    """
    # ===== 步骤1：计算全局相对位置 =====
    torso_pos = self.env_rigid_body_pos[:, self.torso_index]  # 当前躯干位置
    torso_pos_rel = self.target_extra_link_pos[:, self.extra_link_torso_index] - torso_pos
    
    # ===== 步骤2：转换到机器人局部坐标系 =====
    heading = calc_heading_quat_inv(self.rigid_body_quat[:, self.torso_index])
    obs_torso_pos_rel = quat_rotate(heading, torso_pos_rel)
    rel_xy = obs_torso_pos_rel[:, :2]  # 只取XY平面
    
    # ===== 步骤3：可选置零（消融实验）=====
    if self.cfg.deepmimic.zero_torso_xy:
        rel_xy[:] = 0.0  # 禁用这个观测
    
    # ===== 步骤4：添加噪声 =====
    rel_xy += self.cfg.noise.noise_scales.rel_xy * torch.randn_like(rel_xy)
    
    # ===== 步骤5：里程计更新频率随机化（模拟真实传感器延迟）=====
    if self.cfg.domain_rand.randomize_odom_update_frequency:
        # 不是每步都更新观测，模拟低频传感器
        update = torch.remainder(
            self.episode_length_buf + self.odom_update_frequency_offset,
            self.odom_update_frequency
        ) == 0
        
        # 不更新的步骤保持旧值
        rel_xy[~update] = self.last_rel_xy[~update]
        
        self.last_rel_xy = rel_xy  # 保存供下次使用
    
    # ===== 步骤6：手动控制模式 =====
    if hasattr(self, 'viser_viz') and self.viser_viz.manual_control.value:
        # 手动控制时直接返回速度命令
        manual_offset_target = torch.zeros((self.num_envs, 2), device=self.device)
        lin_vel_scale = 0.5
        
        if self.viser_viz.move_forward.value:
            manual_offset_target[:, 0] = lin_vel_scale
        # ... 其他方向
        
        return manual_offset_target
    
    return rel_xy.view(-1, 2)  # (4096, 2)
```

### 4.5 相对偏航 (_obs_torso_yaw_rel) - 根方向组件
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:771-826`

```python
def _obs_torso_yaw_rel(self):
    """
    躯干偏航相对角度（根方向组件！）
    
    告诉机器人目标朝向与当前朝向的角度差
    
    维度：1
    """
    # ===== 步骤1：计算偏航角差 =====
    torso_quat = self.rigid_body_quat[:, self.torso_index]
    target_quat = self.target_extra_link_quat[:, self.extra_link_torso_index]
    
    target_heading = calc_heading(target_quat)      # 目标偏航角
    torso_heading = calc_heading(torso_quat)        # 当前偏航角
    heading_error = target_heading - torso_heading  # 角度差
    
    # ===== 步骤2：归一化到[-π, π]=====
    heading_error = normalize_angle(heading_error)
    
    # ===== 步骤3：可选置零 =====
    if self.cfg.deepmimic.zero_torso_yaw:
        heading_error[:] = 0.0
    
    # ===== 步骤4：添加噪声 =====
    heading_error += self.cfg.noise.noise_scales.rel_yaw * torch.randn_like(heading_error)
    
    # ===== 步骤5：里程计更新频率随机化 =====
    if self.cfg.domain_rand.randomize_odom_update_frequency:
        # 模拟低频传感器更新
        update = torch.remainder(...) == 0
        heading_error[~update] = self.last_torso_yaw_rel[~update]
    
    # ===== 步骤6：手动控制模式 =====
    if hasattr(self, 'viser_viz') and self.viser_viz.manual_control.value:
        manual_ang_vel = torch.zeros((self.num_envs, 1), device=self.device)
        ang_vel_scale = 0.3
        
        if self.viser_viz.rotate_left.value:
            manual_ang_vel[:, 0] = ang_vel_scale
        if self.viser_viz.rotate_right.value:
            manual_ang_vel[:, 0] = -ang_vel_scale
        
        return manual_ang_vel
    
    return heading_error.view(-1, 1)  # (4096, 1)
```

### 4.6 目标关节 (_obs_target_joints) - 参考核心
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:850-852`

```python
def _obs_target_joints(self):
    """
    目标关节位置观察（参考的核心！）
    
    直接告诉机器人每个关节应该在什么角度
    这是MCPT策略与蒸馏策略的主要区别
    
    数据来源：
    - self.target_motors 来自动作捕捉数据
    - 在 update_replay_data() 中更新
    - 每步从 replay_data_loader.get_current_data() 获取
    
    维度：23
    """
    return (self.target_motors - self.default_dof_pos) * self.obs_scales.dof_pos
    # 返回相对默认姿态的关节角度差
    # 经过归一化缩放
```

### 4.7 目标姿态 (_obs_target_root_roll/pitch) - 参考组件
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:854-865`

```python
def _obs_target_root_roll(self):
    """
    目标根部滚转角（参考组件！）
    
    告诉机器人根部（骨盆）应该有多少滚转角度
    
    维度：1
    """
    return normalize_angle(get_roll(self.target_root_quat)).unsqueeze(1)

def _obs_target_root_pitch(self):
    """
    目标根部俯仰角（参考组件！）
    
    告诉机器人根部应该有多少俯仰角度
    
    维度：1
    """
    return normalize_angle(get_pitch(self.target_root_quat)).unsqueeze(1)

def _obs_target_root_yaw(self):
    """
    目标根部偏航角
    
    维度：1
    """
    return normalize_angle(get_yaw(self.target_root_quat)).unsqueeze(1)
```

### 4.8 传感器观测
**配置位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic_config.py:467-530`

```python
sensor_cfgs = [
    # [1] 地形高度场传感器（清洁版）
    HeightfieldCfg(
        name="terrain_height",
        body_name="torso_link",          # 传感器安装在躯干上
        size=(1.0, 1.0),                 # 感知1米×1米区域
        resolution=0.1,                  # 10cm分辨率 → 10×10网格 = 100点
        max_distance=5.0,                # 最大感知距离5米
        use_float=True,                  # 使用float32精度
        white_noise_scale=0.0,           # 无噪声
        # ... 其他噪声均为0
    ),
    # 返回：(4096, 10, 10) = (4096, 100)
    
    # [2] 地形高度场传感器（带噪声版，用于sim2real）
    HeightfieldCfg(
        name="terrain_height_noisy",
        body_name="torso_link",
        size=(1.0, 1.0),
        resolution=0.1,
        max_distance=5.0,
        use_float=True,
        white_noise_scale=0.02,          # 2%白噪声
        offset_noise_scale=0.02,         # 2%偏移噪声
        roll_noise_scale=0.04,           # 4%横滚噪声
        pitch_noise_scale=0.04,          # 4%俯仰噪声
        yaw_noise_scale=0.08,            # 8%偏航噪声
        max_delay=3,                     # 最大3步延迟
        update_frequency_min=1,          # 最小更新频率
        update_frequency_max=5,          # 最大更新频率（模拟低频传感器）
        bad_distance_prob=0.01,          # 1%概率返回错误距离
    ),
    # 返回：(4096, 10, 10) = (4096, 100)
    
    # [3] 根部高度传感器（单点）
    HeightfieldCfg(
        name="root_height",
        body_name="pelvis",              # 安装在骨盆
        size=(0.0, 0.0),                 # 单点测量
        resolution=0.1,
        max_distance=5.0,
        use_float=True,
    ),
    # 返回：(4096, 1, 1) → squeeze → (4096, 1)
    
    # [4] 多关节高度传感器
    MultiLinkHeightCfg(
        name="link_heights",
        body_name="pelvis",              # 参考身体
        max_distance=5.0,
        link_names=tracked_body_names,   # 13个跟踪的身体部位
        use_float=True,
    ),
    # 返回：(4096, 13) - 13个身体部位各自的高度
]
```

### 4.9 教师检查点索引 - 多教师支持
**位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic.py:315-322`

```python
def _obs_teacher_checkpoint_index(self):
    """
    教师检查点索引观察
    
    用途：支持多教师策略
    - 不同动作片段可以对应不同的教师模型
    - 策略网络根据这个索引选择使用哪个教师的输出
    
    例如：
    - AMASS走路数据 → 教师0
    - AMASS跳舞数据 → 教师1
    - 人类视频1 → 教师2
    - 人类视频2 → 教师3
    
    维度：1
    """
    # 获取当前环境使用的动作片段索引
    row_indices = self.replay_data_loader.episode_indices  # (4096,)
    
    # 映射到教师检查点索引
    checkpoint_indices = self.terrain_to_checkpoint_idx[row_indices]  # (4096,)
    
    return checkpoint_indices
```

### 4.10 教师观测组合
**位置**: `simulation/videomimic_gym/legged_gym/envs/base/robot_deepmimic.py:1030-1040`

```python
def _manual_obs_teacher(self):
    """
    教师观测组合（用于蒸馏）
    
    组合MCPT教师策略需要的所有观测：
    - 本体感知历史
    - 根方向历史  
    - 参考关节和姿态
    
    学生策略通过模仿教师的动作来学习
    
    维度：415
    """
    return torch.cat((
        # 本体感知历史 (5帧 × 75维)
        self.obs_dict['history_torso_real'].view(self.num_envs, -1),    # 375
        
        # 根方向历史
        self.obs_dict['history_torso_xy_rel'].view(self.num_envs, -1),  # 10 (5帧×2)
        self.obs_dict['history_torso_yaw_rel'].view(self.num_envs, -1), # 5 (5帧×1)
        
        # 参考信息
        self.obs_dict['target_joints'].view(self.num_envs, -1),         # 23
        self.obs_dict['target_root_roll'].view(self.num_envs, -1),      # 1
        self.obs_dict['target_root_pitch'].view(self.num_envs, -1),     # 1
    ), dim=-1)
    # 总计：375 + 10 + 5 + 23 + 1 + 1 = 415
```

## 五、策略网络观测处理

### 5.1 MCPT策略配置（完整参考）
**位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic_config.py:734-794`

```python
@configclass
class G1DeepMimicPolicyCfg(LeggedRobotPolicyCfg):
    """
    G1深度模仿策略配置（MCPT - MoCap Pre-Training）
    
    定义Actor和Critic网络使用哪些观测
    """
    init_noise_std = 0.8  # 策略初始化噪声标准差
    
    @configclass
    class ObsProcActor:
        """
        Actor网络观测处理配置
        
        Actor输入观测（用于生成动作）：
        1. 本体感知历史 (375维)
        2. 根方向历史 (15维)
        3. 参考关节和姿态 (25维)
        
        总计：415维
        """
        # === 本体感知（历史）===
        history_torso_real = {'type': 'flatten'}
        # 处理：(4096, 5, 75) → flatten → (4096, 375)
        # 包含：5帧的角速度+重力+关节状态+动作历史
        
        # === 根方向（历史）===
        history_torso_xy_rel = {'type': 'flatten'}
        # 处理：(4096, 5, 2) → flatten → (4096, 10)
        # 包含：5帧的相对XY位置
        
        history_torso_yaw_rel = {'type': 'flatten'}
        # 处理：(4096, 5, 1) → flatten → (4096, 5)
        # 包含：5帧的相对偏航角
        
        # === 参考关节（当前帧）- 核心！ ===
        target_joints = {'type': 'identity'}
        # 处理：(4096, 23) → identity → (4096, 23)
        # 包含：目标关节角度
        
        # === 参考姿态（当前帧）- 核心！ ===
        target_root_roll = {'type': 'identity'}
        # 处理：(4096, 1) → identity → (4096, 1)
        
        target_root_pitch = {'type': 'identity'}
        # 处理：(4096, 1) → identity → (4096, 1)
        
        # 注意：注释掉的观测不会被使用
        # target_root_yaw = {'type': 'flatten'}  # 未使用
        # phase = {'type': 'identity'}  # 未使用
        # terrain_height = {...}  # 未使用（这个版本不用地形）
    
    obs_proc_actor = ObsProcActor()
    
    @configclass
    class ObsProcCritic:
        """
        Critic网络观测处理配置
        
        Critic输入观测（用于价值估计）：
        Critic通常使用更多信息，因为它不需要部署到真机
        """
        # === 完整状态信息（Critic特权）===
        torso = {'type': 'identity'}
        # 完整躯干信息，包含线速度等
        
        deepmimic = {'type': 'identity'}
        # 完整参考动作信息（129维）
        
        # === 本体感知和根方向（同Actor）===
        history_torso_real = {'type': 'flatten'}
        history_torso_xy_rel = {'type': 'flatten'}
        history_torso_yaw_rel = {'type': 'flatten'}
        
        # === 参考信息（同Actor）===
        target_joints = {'type': 'identity'}
        target_root_roll = {'type': 'identity'}
        target_root_pitch = {'type': 'identity'}
    
    obs_proc_critic = ObsProcCritic()
```

### 5.2 地形策略配置（完整参考+地形）
**位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic_config.py:797-859`

```python
@configclass
class G1DeepmimicHeightFieldPolicyCfg(G1DeepMimicPolicyCfg):
    """
    地形感知策略配置（阶段2：地形上的跟踪）
    
    在MCPT基础上增加地形感知能力
    """
    
    @configclass
    class ObsProcActor:
        # === 同MCPT的观测 ===
        history_torso_real = {'type': 'flatten'}       # 本体感知
        history_torso_xy_rel = {'type': 'flatten'}     # 根方向
        history_torso_yaw_rel = {'type': 'flatten'}    # 根方向
        target_joints = {'type': 'identity'}           # 参考关节
        target_root_roll = {'type': 'identity'}        # 参考姿态
        target_root_pitch = {'type': 'identity'}       # 参考姿态
        
        # === 新增：地形感知 ===
        terrain_height = {
            'type': 'flatten_then_embed_with_attention',
            'output_dim': 415
        }
        # 处理流程：
        # (4096, 10, 10) → flatten → (4096, 100)
        # → embed → (4096, hidden_dim)
        # → attention → (4096, 415)
        # 
        # 作用：
        # - 提取地形特征
        # - 使用注意力机制聚焦重要区域
        # - 适应复杂地形
    
    obs_proc_actor = ObsProcActor()
    
    @configclass
    class ObsProcCritic:
        torso = {'type': 'identity'}
        deepmimic = {'type': 'identity'}
        history_torso_real = {'type': 'flatten'}
        history_torso_xy_rel = {'type': 'flatten'}
        history_torso_yaw_rel = {'type': 'flatten'}
        target_joints = {'type': 'identity'}
        target_root_roll = {'type': 'identity'}
        target_root_pitch = {'type': 'identity'}
        
        # Critic也使用地形信息（不同维度）
        terrain_height = {
            'type': 'flatten_then_embed_with_attention',
            'output_dim': 623
        }
    
    obs_proc_critic = ObsProcCritic()
```

### 5.3 蒸馏平面策略配置（仅根方向）
**位置**: `simulation/videomimic_gym/legged_gym/envs/g1/g1_deepmimic_config.py:1067-1132`

```python
@configclass
class G1DeepMimicCfgRootPolicyCfg(G1DeepMimicPolicyCfg):
    """
    根方向策略配置（蒸馏平面策略）
    
    只使用根方向，不使用参考关节
    用于对比实验：验证参考关节的重要性
    """
    
    @configclass
    class ObsProcActor:
        # === 本体感知（历史）===
        history_torso_real = {'type': 'flatten'}       # 375维
        
        # === 根方向（历史）- 仅有的参考信息！ ===
        history_torso_xy_rel = {'type': 'flatten'}     # 10维
        history_torso_yaw_rel = {'type': 'flatten'}    # 5维
        
        # === 注意：没有以下参考信息！ ===
        # target_joints = {'type': 'identity'}          # 被注释掉
        # target_root_roll = {'type': 'identity'}       # 被注释掉
        # target_root_pitch = {'type': 'identity'}      # 被注释掉
        
        # 总输入维度：375 + 10 + 5 = 390维
        # 对比MCPT的415维，少了25维的参考关节和姿态
    
    obs_proc_actor = ObsProcActor()
    
    @configclass
    class ObsProcCritic:
        # Critic仍然使用完整信息（用于价值估计）
        torso = {'type': 'identity'}
        deepmimic = {'type': 'identity'}
        history_torso_real = {'type': 'flatten'}
        history_torso_xy_rel = {'type': 'flatten'}
        history_torso_yaw_rel = {'type': 'flatten'}
        
        # Critic使用参考信息（帮助价值估计）
        target_joints = {'type': 'identity'}
        target_root_roll = {'type': 'identity'}
        target_root_pitch = {'type': 'identity'}
        
        # Critic使用带噪声地形（更真实）
        terrain_height_noisy = {
            'type': 'flatten_then_embed_with_attention_to_hidden'
        }
    
    obs_proc_critic = ObsProcCritic()
    
    # 更深的网络（提高容量）
    actor_hidden_dims = [1024, 512, 256, 128]
    critic_hidden_dims = [1024, 512, 256, 128]
```

## 六、观测维度详细对照表

| 观测组件 | 原始形状 | 展平后维度 | 数据来源 | 更新频率 | 是否参考 | 说明 |
|---------|---------|----------|---------|---------|---------|------|
| **本体感知类** |
| `torso_real` | (4096,75) | 75 | 仿真状态 | 每步 | ✗ | 角速度+重力+关节+动作 |
| `history_torso_real` | (4096,5,75) | 375 | 历史缓冲 | 每步 | ✗ | 5帧本体感知历史 |
| **参考动作类（完整）** |
| `deepmimic` | (4096,129) | 129 | 回放数据 | 每步 | ✓ | 完整参考动作信息 |
| `target_joints` | (4096,23) | 23 | 回放数据 | 每步 | ✓ | 目标关节角度★ |
| `target_root_roll` | (4096,1) | 1 | 回放数据 | 每步 | ✓ | 目标滚转角★ |
| `target_root_pitch` | (4096,1) | 1 | 回放数据 | 每步 | ✓ | 目标俯仰角★ |
| **根方向类** |
| `deepmimic_lin_ang_vel` | (4096,6) | 6 | 回放数据 | 每步 | ✓ | 目标速度■ |
| `history_deepmimic_lin_ang_vel` | (4096,5,6) | 30 | 历史缓冲 | 每步 | ✓ | 5帧速度历史■ |
| `torso_xy_rel` | (4096,2) | 2 | 计算 | 可变 | ✓ | 相对XY位置■ |
| `history_torso_xy_rel` | (4096,5,2) | 10 | 历史缓冲 | 每步 | ✓ | 5帧XY历史■ |
| `torso_yaw_rel` | (4096,1) | 1 | 计算 | 可变 | ✓ | 相对偏航角■ |
| `history_torso_yaw_rel` | (4096,5,1) | 5 | 历史缓冲 | 每步 | ✓ | 5帧偏航历史■ |
| **地形感知类** |
| `terrain_height` | (4096,10,10) | 100 | 传感器 | 每步 | ✗ | 清洁高度场 |
| `terrain_height_noisy` | (4096,10,10) | 100 | 传感器 | 可变 | ✗ | 带噪声高度场 |
| `root_height` | (4096,1) | 1 | 传感器 | 每步 | ✗ | 根部高度 |
| `link_heights` | (4096,13) | 13 | 传感器 | 每步 | ✗ | 多关节高度 |
| **其他** |
| `phase` | (4096,2) | 2 | 回放数据 | 每步 | ✓ | 动作相位 |
| `teacher_checkpoint_index` | (4096,) | 1 | 配置 | 重置时 | ✗ | 教师索引 |
| `teacher` | (4096,415) | 415 | 组合 | 每步 | ✓ | 教师完整观测 |

**图例**：
- ★ = 参考关节（MCPT有，蒸馏平面策略无）
- ■ = 根方向（所有策略都有）

## 七、三种策略的观测对比

### MCPT策略（Motion Capture Pre-Training）